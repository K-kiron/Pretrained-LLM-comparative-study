{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9454394b-7e7c-47a0-b7a6-b00f128ea5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import numpy as np\n",
    "from transformers import MambaForCausalLM, AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "629261c3-1515-42c7-9ef8-c3e76b8318b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "model_id = \"state-spaces/mamba-130m-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"left\"\n",
    "\n",
    "# special_tokens_dict = {\"cls_token\": \"<CLS>\", \"sep_token\": \"<SEP>\"}\n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "#       (str(\"[SEP]\"), 50278), (str(\"[CLS]\"), 50277)\n",
    "# )\n",
    "\n",
    "max_length = 512 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "datasets = load_dataset(\"squad\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4f320cc1-be68-424a-bb92-6aa5bf0b460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18551, 5671, 8572, 13, 253, 2143, 556, 247, 10503, 1894, 15, 2058, 412, 253, 11505, 16790, 434, 5328, 34074, 310, 247, 14072, 23957, 273, 253, 8237, 6393, 15, 41853, 275, 2914, 273, 253, 11505, 16790, 285, 10268, 352, 13, 310, 247, 14295, 23957, 273, 2828, 342, 6174, 598, 42750, 342, 253, 13691, 346, 39685, 614, 2006, 3189, 30542, 5210, 3446, 10209, 281, 253, 11505, 16790, 310, 253, 42385, 3737, 273, 253, 50179, 15382, 15, 41853, 3212, 253, 40683, 3737, 310, 253, 443, 8601, 936, 13, 247, 38005, 1659, 273, 15851, 285, 12906, 15, 733, 310, 247, 36804, 273, 253, 7753, 85, 936, 387, 418, 454, 3229, 13, 6181, 835, 253, 8237, 6393, 34719, 15376, 5420, 281, 11877, 10246, 324, 5464, 36920, 67, 343, 528, 275, 1283, 3680, 15, 2058, 253, 990, 273, 253, 2022, 4446, 313, 395, 275, 247, 1480, 1386, 326, 23417, 949, 495, 38490, 285, 253, 7284, 399, 485, 582, 310, 247, 2969, 13, 4980, 8805, 23957, 273, 6393, 15, 187, 187, 50, 27, 1916, 5207, 858, 253, 8237, 6393, 14163, 3176, 275, 1283, 3680, 275, 418, 454, 3229, 6181, 32, 187, 34, 27, 11877, 10246, 324, 5464, 36920, 67, 343, 528, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "9\n",
      "[11877, 10246, 324, 5464, 36920, 67, 343, 528, 0]\n",
      " Saint Bernadette Soubirous<|endoftext|>\n",
      "[11877, 10246, 324, 5464, 36920, 67, 343, 528, 0]\n",
      " Saint Bernadette Soubirous<|endoftext|>\n",
      "[ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100 11877 10246   324  5464 36920    67\n",
      "   343   528     0  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100]\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][0]\n",
    "# print(example[\"question\"])\n",
    "# print(example[\"context\"])\n",
    "# print(example[\"answers\"][\"text\"][0])\n",
    "\n",
    "tokenized_example = tokenizer(\n",
    "    f\"{example['context']}\\n\\nQ: {example['question']}\\nA: {example['answers']['text'][0]}<|endoftext|>\",\n",
    "    # example[\"context\"],\n",
    "    # example[\"question\"],\n",
    "    # [example[\"answers\"][\"text\"][0]],\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    ")\n",
    "\n",
    "x = tokenized_example[\"input_ids\"]\n",
    "a = tokenized_example[\"attention_mask\"]\n",
    "# print(tokenizer.decode(x))\n",
    "a = np.array(a)\n",
    "a1 = np.count_nonzero(a) - 512\n",
    "print(x)\n",
    "\n",
    "answer_code = tokenizer(\" \"+example[\"answers\"][\"text\"][0] + \"<|endoftext|>\")[\"input_ids\"]\n",
    "answer_length = len(answer_code)\n",
    "\n",
    "print(answer_length)\n",
    "print(answer_code)\n",
    "print(tokenizer.decode(answer_code))\n",
    "print(x[a1-answer_length:a1])\n",
    "print(tokenizer.decode(x[a1-answer_length:a1]))\n",
    "\n",
    "labels = np.ones_like(a) * -100\n",
    "labels[a1-answer_length:a1] = x[a1-answer_length:a1]\n",
    "# print(np.array(x))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "646fd95a-d3ef-49d2-9122-199b936ae925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|████████████████████████████████████████████████| 87425/87425 [00:19<00:00, 4401.14 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████| 10514/10514 [00:02<00:00, 4206.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87425\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10514\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def length_filter(example):\n",
    "    # Calculate the total length of question, context, and answers (assuming only one answer per question)\n",
    "    total_length = len(tokenizer(f\"{example['context']}\\n\\nQ: {example['question']}\\nA: {example['answers']['text'][0]}<|endoftext|>\")[\"input_ids\"])\n",
    "    return total_length <= 512\n",
    "\n",
    "datasets = datasets.filter(length_filter)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a1c93eb6-b013-474e-87cd-f1487a27fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████| 87425/87425 [00:41<00:00, 2111.54 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████| 10514/10514 [00:05<00:00, 2052.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_train_features(example):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    example[\"question\"] = example[\"question\"].lstrip()\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_example = tokenizer(\n",
    "        f\"{example['context']}\\n\\nQ: {example['question']}\\nA: {example['answers']['text'][0]}<|endoftext|>\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Let's label those examples!\n",
    "    input_ids = tokenized_example[\"input_ids\"]\n",
    "    attention_mask = tokenized_example[\"attention_mask\"]\n",
    "    end_pos = np.count_nonzero(attention_mask) - max_length\n",
    "\n",
    "    answer_code = tokenizer(\" \"+example[\"answers\"][\"text\"][0] + \"<|endoftext|>\")[\"input_ids\"]\n",
    "    answer_length = len(answer_code)\n",
    "\n",
    "    labels = np.ones_like(attention_mask) * -100\n",
    "    labels[end_pos-answer_length:end_pos] = input_ids[end_pos-answer_length:end_pos]\n",
    "    tokenized_example[\"labels\"] = labels\n",
    "   \n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_datasets = datasets.map(prepare_train_features, batched=False, remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1952bcc1-ec92-4229-8932-8dd8540d4f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 10514\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "5f71a3f2-2cbd-4e65-852b-9ed5bce0a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaForCausalLM(\n",
      "  (backbone): MambaModel(\n",
      "    (embeddings): Embedding(50280, 768)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x MambaBlock(\n",
      "        (norm): MambaRMSNorm()\n",
      "        (mixer): MambaMixer(\n",
      "          (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
      "          (act): SiLU()\n",
      "          (in_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
      "          (x_proj): Linear(in_features=1536, out_features=80, bias=False)\n",
      "          (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
      "          (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_f): MambaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MambaForCausalLM.from_pretrained(model_id)\n",
    "model.config.keys_to_ignore_at_inference = [\"cache_params\", \"hidden_states\"]\n",
    "model = model.to(\"cuda:0\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3b6b5cc2-28e7-4880-9a0e-a8980d394e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"Mamba-finetuned-squadCausal\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    warmup_ratio=0.1,\n",
    "    # fp16=True,\n",
    "    # max_steps=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    # data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "de9cd1cf-dcdd-4a09-b748-a22ae560c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"Mamba-finetuned-squadCausal/Final\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Mamba-finetuned-squadCausal/Final\")\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e0a37da1-e2c0-49c9-b72d-4392537d14f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████| 10514/10514 [08:11<00:00, 21.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 10514\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers', 'guess'],\n",
      "    num_rows: 10514\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_validation_features(example):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    example[\"question\"] = example[\"question\"].lstrip()\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    # tokenized_example = tokenizer(\n",
    "    #     f\"{example['context']}\\n\\nQ: {example['question']}\\nA:\",\n",
    "    #     max_length=max_length,\n",
    "    #     truncation=True,\n",
    "    # )\n",
    "    \n",
    "    text = f\"{example['context']}\\n\\nQ: {example['question']}\\nA:\"\n",
    "    input_ids = torch.LongTensor([tokenizer.encode(text)]).cuda()\n",
    "\n",
    "    # example[\"input_ids\"] = tokenized_example[\"input_ids\"]\n",
    "    # input_ids = torch.LongTensor([tokenized_example[\"input_ids\"]]).cuda()\n",
    "    out = model.generate(input_ids, max_length=max_length, eos_token_id=tokenizer.eos_token_id)\n",
    "    decoded = tokenizer.batch_decode(out)[0]\n",
    "    cleaned = decoded.replace(text, \"\")\n",
    "    cleaned = cleaned.replace(\"<|endoftext|>\", \"\")\n",
    "    guess = cleaned.split(\"\\n\\n\")[0].strip()\n",
    "    example[\"guess\"] = guess\n",
    "   \n",
    "    return example\n",
    "\n",
    "tokenized_validsets = datasets[\"validation\"].map(prepare_validation_features, batched=False)\n",
    "print(datasets[\"validation\"])\n",
    "print(tokenized_validsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "409f31ad-17ec-41c2-b0f2-760f55cc6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did Super Bowl 50 take place?\n",
      "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\n"
     ]
    }
   ],
   "source": [
    "text = datasets[\"validation\"][2]\n",
    "text[\"question\"] = text[\"question\"].lstrip()\n",
    "print(text[\"question\"])\n",
    "\n",
    "text = f\"{text['context']}\\n\\nQ: {text['question']}\\nA:\"\n",
    "\n",
    "input_ids = torch.LongTensor([tokenizer.encode(text)]).cuda()\n",
    "out = model.generate(input_ids, max_length=max_length, eos_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(out)[0]\n",
    "# print(decoded)\n",
    "cleaned = decoded.replace(text, \"\")\n",
    "cleaned = cleaned.replace(\"<|endoftext|>\", \"\")\n",
    "guess = cleaned.split(\"\\n\\n\")[0].strip()\n",
    "print(guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bb29c197-b271-4a19-ae5c-4c96714600e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 58.37930378542895, 'f1': 67.6197732858846}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "squad_metric = load(\"squad\")\n",
    "predictions = [{\"id\": ex[\"id\"], 'prediction_text': ex[\"guess\"]} for ex in tokenized_validsets]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in tokenized_validsets]\n",
    "results = squad_metric.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "be8c842e-dd3f-498b-9621-b79c54a6841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be8e613aeaaa14008c90d2', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'question': 'What day was the game played on?', 'answers': {'text': ['February 7, 2016', 'February 7', 'February 7, 2016'], 'answer_start': [334, 334, 334]}, 'guess': 'February 7, 2016'}\n"
     ]
    }
   ],
   "source": [
    "text = tokenized_validsets[6]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
