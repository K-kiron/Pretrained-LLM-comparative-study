{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIVdIPd-uBK"
      },
      "source": [
        "Ref: https://github.com/EleutherAI/lm-evaluation-harness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD9ALckB-IGp"
      },
      "source": [
        "## Language model evaluation harness starter resource\n",
        "\n",
        "This showcases how to evaluate your models on the LM Eval harness from EleutherAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zav0yCBF990_",
        "outputId": "6f2735fa-7257-4939-9b33-8243d4132860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lm-eval\n",
            "  Downloading lm_eval-0.4.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.21.0 (from lm-eval)\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from lm-eval)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from lm-eval)\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines (from lm-eval)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.10.0)\n",
            "Collecting peft>=0.2.0 (from lm-eval)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm-eval)\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm-eval)\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm-eval)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm-eval)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (1.2.2)\n",
            "Collecting sqlitedict (from lm-eval)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.2.1+cu121)\n",
            "Collecting tqdm-multiprocess (from lm-eval)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (4.40.0)\n",
            "Collecting zstandard (from lm-eval)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from lm-eval)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting word2number (from lm-eval)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval) (10.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (4.66.2)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm-eval)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.16.0->lm-eval)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (3.9.5)\n",
            "Collecting huggingface-hub (from accelerate>=0.21.0->lm-eval)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate->lm-eval)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm-eval)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval) (0.19.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm-eval) (23.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (67.7.2)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval)\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval)\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval)\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm-eval)\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm-eval) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm-eval) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm-eval) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm-eval) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm-eval) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.7)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->lm-eval) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm-eval) (1.3.0)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=15e30184d071e2100a9a6a1a9e5984b7daaa3bbaa27410254f51ffa76d19a141\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=8b60eea9975fd109cb44f53dcc02361517edab238f3006c20ab46cd282e76714\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=113ecf7acc397b210a7e6fa2e4b54599fe010ede365753da4536ff14802fea21\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, zstandard, xxhash, tcolorpy, pybind11, portalocker, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, jsonlines, dill, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, datasets, DataProperty, tabledata, evaluate, accelerate, pytablewriter, peft, lm-eval\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed DataProperty-1.0.1 accelerate-0.29.3 colorama-0.4.6 datasets-2.19.0 dill-0.3.8 evaluate-0.4.1 huggingface-hub-0.22.2 jsonlines-4.0.0 lm-eval-0.4.2 mbstrdecoder-1.1.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pathvalidate-3.2.0 peft-0.10.0 portalocker-2.8.2 pybind11-2.12.0 pytablewriter-1.2.0 responses-0.18.0 rouge-score-0.1.2 sacrebleu-2.4.2 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lm-eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icGr9F6nLrr0",
        "outputId": "7014b532-df84-4521-945e-8d7133911ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.0\n",
            "    Uninstalling transformers-4.40.0:\n",
            "      Successfully uninstalled transformers-4.40.0\n",
            "Successfully installed transformers-4.40.1\n"
          ]
        }
      ],
      "source": [
        "! pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QQCqxZz-uTE",
        "outputId": "c10ba573-0581-429b-954f-9dd9fb9208a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lm-evaluation-harness'...\n",
            "remote: Enumerating objects: 33245, done.\u001b[K\n",
            "remote: Counting objects: 100% (550/550), done.\u001b[K\n",
            "remote: Compressing objects: 100% (341/341), done.\u001b[K\n",
            "remote: Total 33245 (delta 294), reused 407 (delta 207), pack-reused 32695\u001b[K\n",
            "Receiving objects: 100% (33245/33245), 22.97 MiB | 20.43 MiB/s, done.\n",
            "Resolving deltas: 100% (23154/23154), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf lm-evaluation-harness/\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyHea5W5HJWS",
        "outputId": "d8931168-ccfe-4692-dac2-102d5e488928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt\n",
            "  Downloading https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m16.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.11.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.15.0)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.1.99)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2024.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt) (3.2.2)\n",
            "Building wheels for collected packages: bleurt\n",
            "  Building wheel for bleurt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454005 sha256=05694360543ede58fada5681e36f298fb700d241e0dd5136a3ab99c0ce35b877\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-15935pw_/wheels/d6/8b/6d/18f51ff9a19a24c6f73dd939e4ce5cd80972275d1ec0c25dc0\n",
            "Successfully built bleurt\n",
            "Installing collected packages: bleurt\n",
            "Successfully installed bleurt-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install bleurt@https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA3n-KdD7j0f",
        "outputId": "b84651d9-3a48-43f9-d4e7-1bae32168b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lm_eval[zeno] in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.29.3)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.19.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.10.0)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.10.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.12.0)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (1.2.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (4.40.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.22.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (10.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lm_eval[zeno]) (2.0.3)\n",
            "Collecting zeno-client (from lm_eval[zeno])\n",
            "  Downloading zeno_client-0.1.16-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[zeno]) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (0.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[zeno]) (3.9.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->lm_eval[zeno]) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[zeno]) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[zeno]) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[zeno]) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[zeno]) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[zeno]) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[zeno]) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[zeno]) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[zeno]) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[zeno]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[zeno]) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[zeno]) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[zeno]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval[zeno]) (12.4.127)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval[zeno]) (0.19.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval[zeno]) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[zeno]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[zeno]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[zeno]) (2024.1)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (67.7.2)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (3.2.0)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (0.1.6)\n",
            "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[zeno]) (1.3.2)\n",
            "Collecting arrow-json<0.10.0,>=0.9.0 (from zeno-client->lm_eval[zeno])\n",
            "  Downloading arrow_json-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from zeno-client->lm_eval[zeno])\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.0 in /usr/local/lib/python3.10/dist-packages (from zeno-client->lm_eval[zeno]) (2.7.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[zeno]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[zeno]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[zeno]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[zeno]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[zeno]) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval[zeno]) (5.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->zeno-client->lm_eval[zeno])\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.0->zeno-client->lm_eval[zeno]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.0->zeno-client->lm_eval[zeno]) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[zeno]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[zeno]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[zeno]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[zeno]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval[zeno]) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval[zeno]) (8.1.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval[zeno]) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=3de55173e2c5e59bc6b5918d128917fa04d926aaacbd43d1bfc3e94453734a0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, arrow-json, zeno-client\n",
            "Successfully installed arrow-json-0.9.0 littleutils-0.2.2 outdated-0.2.2 zeno-client-0.1.16\n"
          ]
        }
      ],
      "source": [
        "!pip install lm_eval[zeno]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8WMvjwl9QE6",
        "outputId": "6c1bf19f-ffbc-46a2-ccb3-6e8ab225f2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lm_eval[wandb] in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.29.3)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.19.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.10.0)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.10.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.12.0)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (1.2.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (4.40.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.22.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (10.1.0)\n",
            "Collecting wandb>=0.16.3 (from lm_eval[wandb])\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lm_eval[wandb]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[wandb]) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[wandb]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[wandb]) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[wandb]) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval[wandb]) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (0.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval[wandb]) (3.9.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->lm_eval[wandb]) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[wandb]) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[wandb]) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval[wandb]) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[wandb]) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[wandb]) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[wandb]) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[wandb]) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval[wandb]) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[wandb]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[wandb]) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval[wandb]) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval[wandb]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval[wandb]) (12.4.127)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval[wandb]) (0.19.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.3->lm_eval[wandb]) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.3->lm_eval[wandb]) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.3->lm_eval[wandb]) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.3->lm_eval[wandb]) (3.20.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval[wandb]) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[wandb]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[wandb]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lm_eval[wandb]) (2024.1)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (3.2.0)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (0.1.6)\n",
            "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval[wandb]) (1.3.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[wandb]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[wandb]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[wandb]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[wandb]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval[wandb]) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval[wandb]) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[wandb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[wandb]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[wandb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval[wandb]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval[wandb]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval[wandb]) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.16.3->lm_eval[wandb])\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "!pip install lm_eval[wandb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy29upUg9CYR"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "E5OikFBs-WX8",
        "outputId": "73c4d3ea-904b-4751-a4d3-3e368942d96e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct9IyZu5RXEa"
      },
      "source": [
        "## Pythia 160m"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0-shot"
      ],
      "metadata": {
        "id": "HJfcWm45RXEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097c974d-1ecd-4f04-9d65-3cb8b69af913",
        "id": "tVdv5pWLRXEf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 19:05:44.034597: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 19:05:44.034640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 19:05:44.036210: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 19:05:45.236177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 18.8MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_190551-30v5hn08\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvague-mountain-5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-lm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-lm/runs/30v5hn08\u001b[0m\n",
            "2024-04-27:19:05:52,146 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:19:05:58,186 INFO     [__main__.py:335] Selected Tasks: ['squadv2', 'sst2', 'wikitext']\n",
            "2024-04-27:19:05:58,186 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:19:05:58,194 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:19:05:58,290 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 569/569 [00:00<00:00, 1.55MB/s]\n",
            "model.safetensors: 100% 375M/375M [00:01<00:00, 229MB/s]\n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 913kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.04MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 254kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 16.6MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 60.0MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.10MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 295897.32 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 270274.96 examples/s]\n",
            "2024-04-27:19:06:18,274 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-27:19:06:18,274 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 21.8MB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 7.34MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 317kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 655kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 882351.48 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 297062.47 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 472696.35 examples/s]\n",
            "2024-04-27:19:06:26,887 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:19:06:26,887 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:19:06:26,887 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:19:06:26,888 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:19:06:26,888 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-27:19:06:26,888 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Downloading builder script: 100% 10.7k/10.7k [00:00<00:00, 16.0MB/s]\n",
            "Downloading readme: 100% 7.78k/7.78k [00:00<00:00, 14.3MB/s]\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-27:19:06:28,789 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "Downloading data: 100% 4.72M/4.72M [00:00<00:00, 70.5MB/s]\n",
            "Generating test split: 62 examples [00:00, 2888.32 examples/s]\n",
            "Generating train split: 629 examples [00:00, 2761.41 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 3529.72 examples/s]\n",
            "2024-04-27:19:06:29,705 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 551.76it/s]\n",
            "2024-04-27:19:06:29,822 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:00<00:00, 2064.25it/s]\n",
            "2024-04-27:19:06:30,277 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 18932.67it/s]\n",
            "2024-04-27:19:06:31,689 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "100% 62/62 [00:08<00:00,  7.33it/s]\n",
            "2024-04-27:19:06:46,962 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/13617 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 32\n",
            "Running loglikelihood requests: 100% 13617/13617 [00:26<00:00, 509.64it/s] \n",
            "2024-04-27:19:07:31,834 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "Running generate_until requests: 100% 11873/11873 [1:32:55<00:00,  2.13it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/lm_eval/tasks/squadv2/task.py:39: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  squad_metric = datasets.load_metric(\"squad_v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 6.46kB [00:00, 9.49MB/s]       \n",
            "Downloading extra modules: 11.3kB [00:00, 13.5MB/s]       \n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 102411 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 158814 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105896 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168850 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112550 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 133575 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 166056 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 110696 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 107025 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 157414 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 104922 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 134138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105241 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 215901 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 143866 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 141632 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168281 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112735 bytes\n",
            "2024-04-27:20:41:19,944 INFO     [__main__.py:384] Logging to Weights and Biases failed due to 'metric_list'\n",
            "hf (pretrained=EleutherAI/pythia-160m,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (32)\n",
            "| Tasks  |Version|Filter|n-shot|    Metric     | Value |   |Stderr|\n",
            "|--------|------:|------|-----:|---------------|------:|---|------|\n",
            "|wikitext|      2|none  |     0|word_perplexity|33.4247|±  |N/A   |\n",
            "|        |       |none  |     0|byte_perplexity| 1.9276|±  |N/A   |\n",
            "|        |       |none  |     0|bits_per_byte  | 0.9468|±  |N/A   |\n",
            "|sst2    |      1|none  |     0|acc            | 0.5138|±  |0.0169|\n",
            "|squadv2 |      3|none  |     0|exact          | 1.9961|±  |N/A   |\n",
            "|        |       |none  |     0|f1             | 4.5066|±  |N/A   |\n",
            "|        |       |none  |     0|HasAns_exact   | 0.6410|±  |N/A   |\n",
            "|        |       |none  |     0|HasAns_f1      | 5.6693|±  |N/A   |\n",
            "|        |       |none  |     0|NoAns_exact    | 3.3474|±  |N/A   |\n",
            "|        |       |none  |     0|NoAns_f1       | 3.3474|±  |N/A   |\n",
            "|        |       |none  |     0|best_exact     |50.0716|±  |N/A   |\n",
            "|        |       |none  |     0|best_f1        |50.0716|±  |N/A   |\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/HasAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/NoAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       squadv2/best_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          sst2/acc_stderr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/HasAns_exact 0.64103\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/HasAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/HasAns_f1 5.66926\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             squadv2/NoAns_exact 3.34735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/NoAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                squadv2/NoAns_f1 3.34735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   squadv2/alias squadv2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              squadv2/best_exact 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       squadv2/best_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 squadv2/best_f1 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   squadv2/exact 1.99613\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      squadv2/f1 4.50664\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        sst2/acc 0.51376\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc_stderr 0.01694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      sst2/alias sst2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  wikitext/alias wikitext\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          wikitext/bits_per_byte 0.94678\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/byte_perplexity 1.92756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/word_perplexity 33.42472\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvague-mountain-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-lm/runs/30v5hn08\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-lm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240427_190551-30v5hn08/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=EleutherAI/pythia-160m,trust_remote_code=True \\\n",
        "    --tasks squadv2,sst2,wikitext \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --log_samples \\\n",
        "    --output_path output/pythia-160m \\\n",
        "    --wandb_args project=pythia-160m-lm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-shot"
      ],
      "metadata": {
        "id": "cZn748JKtWK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=EleutherAI/pythia-160m,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 1 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/pythia-160m-1-shot \\\n",
        "    --wandb_args project=pythia-160m-1-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nth09e6HtY5p",
        "outputId": "00fede7b-9d11-4969-b6b7-79085c4c3677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 22:44:24.566874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 22:44:24.566935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 22:44:24.568377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 22:44:25.860180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_224430-j4hkaxeu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstill-frog-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-1-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-1-shot/runs/j4hkaxeu\u001b[0m\n",
            "2024-04-27:22:44:31,642 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:22:44:37,908 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-27:22:44:37,908 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:22:44:37,920 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:22:44:38,008 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 569/569 [00:00<00:00, 1.40MB/s]\n",
            "model.safetensors: 100% 375M/375M [00:09<00:00, 40.1MB/s]\n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 984kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.97MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 222kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 13.0MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 32.9MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.05MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 271835.73 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 338285.25 examples/s]\n",
            "2024-04-27:22:45:06,198 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 1\n",
            "2024-04-27:22:45:06,200 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 15358.43it/s]\n",
            "2024-04-27:22:45:08,258 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "Running generate_until requests:   5% 641/11873 [05:31<1:21:42,  2.29it/s]Traceback (most recent call last):\n",
            "\n",
            "Running generate_until requests:   5% 648/11873 [05:34<1:36:29,  1.94it/s]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkOLlh_HRXEg"
      },
      "outputs": [],
      "source": [
        "!export ZENO_API_KEY=[zen_5EedCPMCr0D4QUdJGI03rKP-iuFNMOsBz8s7t3_OHcY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9o06LhyRXEg"
      },
      "outputs": [],
      "source": [
        "%env ZENO_API_KEY=[zen_5EedCPMCr0D4QUdJGI03rKP-iuFNMOsBz8s7t3_OHcY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioKwkVPWRXEg"
      },
      "outputs": [],
      "source": [
        "!python lm-evaluation-harness/scripts/zeno_visualize.py --data_path output --project_name \"pythia-160m-zeno\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c89dd02-d217-4e51-bbac-2076fbc531c0",
        "id": "TcGum9CuRXEg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc12113-4c90-4c7f-c3bf-b8cfcc2d34dd",
        "id": "cx7XurkfRXEg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lm-evaluation-harness  output  sample_data  wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-shot"
      ],
      "metadata": {
        "id": "m8Ey8dJSXp_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lm_eval --model hf --model_args pretrained=EleutherAI/pythia-160m,trust_remote_code=True --tasks squadv2 --device cuda:0 --batch_size auto --num_fewshot 5 --log_samples --output_path output/pythia-160m-5-shot --wandb_args project=pythia-160m-5-shot"
      ],
      "metadata": {
        "id": "0itVSVBUXsdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=EleutherAI/pythia-160m,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 5 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/pythia-160m-5-shot \\\n",
        "    --wandb_args project=pythia-160m-5-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIn0WWuY1HtP",
        "outputId": "e3a77384-8b4a-40de-e486-d33f5a6bfd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-28 17:52:42.286872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 17:52:42.286924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 17:52:42.288330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 17:52:43.570320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 13.5MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240428_175250-tyzg69db\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvisionary-dew-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-5-shot/runs/tyzg69db\u001b[0m\n",
            "2024-04-28:17:52:51,135 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-28:17:52:56,879 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-28:17:52:56,880 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-28:17:52:56,888 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-28:17:52:56,978 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 569/569 [00:00<00:00, 1.35MB/s]\n",
            "model.safetensors: 100% 375M/375M [00:03<00:00, 118MB/s] \n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 960kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 6.43MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 256kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 13.8MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 56.7MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.17MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 352976.71 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 178719.62 examples/s]\n",
            "2024-04-28:17:53:17,349 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 5\n",
            "2024-04-28:17:53:17,350 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 12072.71it/s]\n",
            "2024-04-28:17:53:19,041 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "Running generate_until requests: 100% 11873/11873 [1:05:00<00:00,  3.04it/s]\n",
            "2024-04-28:18:58:19,528 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 8\n",
            "Running loglikelihood requests: 100% 11873/11873 [04:01<00:00, 49.24it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/lm_eval/tasks/squadv2/task.py:39: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  squad_metric = datasets.load_metric(\"squad_v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 6.46kB [00:00, 4.76MB/s]       \n",
            "Downloading extra modules: 11.3kB [00:00, 14.7MB/s]       \n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-04-28:19:04:15,899 INFO     [__main__.py:384] Logging to Weights and Biases failed due to 'metric_list'\n",
            "hf (pretrained=EleutherAI/pythia-160m,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: auto (8)\n",
            "| Tasks |Version|Filter|n-shot|   Metric   | Value |   |Stderr|\n",
            "|-------|------:|------|-----:|------------|------:|---|------|\n",
            "|squadv2|      3|none  |     5|exact       | 2.0467|±  |N/A   |\n",
            "|       |       |none  |     5|f1          | 4.1041|±  |N/A   |\n",
            "|       |       |none  |     5|HasAns_exact| 3.4244|±  |N/A   |\n",
            "|       |       |none  |     5|HasAns_f1   | 7.5451|±  |N/A   |\n",
            "|       |       |none  |     5|NoAns_exact | 0.6728|±  |N/A   |\n",
            "|       |       |none  |     5|NoAns_f1    | 0.6728|±  |N/A   |\n",
            "|       |       |none  |     5|best_exact  |50.0716|±  |N/A   |\n",
            "|       |       |none  |     5|best_f1     |50.0717|±  |N/A   |\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: squadv2/HasAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    squadv2/HasAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  squadv2/NoAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/NoAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   squadv2/best_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/best_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_exact 3.42443\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: squadv2/HasAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/HasAns_f1 7.54515\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    squadv2/HasAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_exact 0.67283\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  squadv2/NoAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/NoAns_f1 0.67283\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/NoAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/alias squadv2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_exact 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   squadv2/best_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             squadv2/best_f1 50.07168\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/best_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/exact 2.04666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  squadv2/f1 4.10407\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvisionary-dew-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-5-shot/runs/tyzg69db\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-160m-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240428_175250-tyzg69db/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mamba-130m"
      ],
      "metadata": {
        "id": "qFWgj5b68OcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0-shot"
      ],
      "metadata": {
        "id": "o1-k4aOf85Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True \\\n",
        "    --tasks squadv2,sst2,wikitext \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-130m-hf \\\n",
        "    --wandb_args project=mamba-130m-hf"
      ],
      "metadata": {
        "id": "SGaWjjOk8wL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb114593-b954-4f3a-f537-518c3fed4b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 19:39:12.936733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 19:39:12.936786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 19:39:12.938792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 19:39:14.134183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 21.0MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_193919-0974uqm5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfallen-sound-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf/runs/0974uqm5\u001b[0m\n",
            "2024-04-27:19:39:19,941 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:19:39:25,779 INFO     [__main__.py:335] Selected Tasks: ['squadv2', 'sst2', 'wikitext']\n",
            "2024-04-27:19:39:25,779 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:19:39:25,784 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:19:39:25,865 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 895/895 [00:00<00:00, 2.18MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:03<00:00, 144MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 398kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 15.2MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 15.5MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 15.4MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 26.8MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 4.30MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 512925.00 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 485218.76 examples/s]\n",
            "2024-04-27:19:39:45,516 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-27:19:39:45,516 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 42.0MB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 15.6MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 386kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 774kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 1313705.63 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 390209.44 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 428417.52 examples/s]\n",
            "2024-04-27:19:39:52,527 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:19:39:52,527 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:19:39:52,528 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:19:39:52,528 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:19:39:52,528 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-27:19:39:52,528 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Downloading builder script: 100% 10.7k/10.7k [00:00<00:00, 23.5MB/s]\n",
            "Downloading readme: 100% 7.78k/7.78k [00:00<00:00, 20.1MB/s]\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-27:19:39:54,215 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "Downloading data: 100% 4.72M/4.72M [00:00<00:00, 70.9MB/s]\n",
            "Generating test split: 62 examples [00:00, 2904.16 examples/s]\n",
            "Generating train split: 629 examples [00:00, 3462.29 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 4183.22 examples/s]\n",
            "2024-04-27:19:39:54,861 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 560.88it/s]\n",
            "2024-04-27:19:39:54,975 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:00<00:00, 2156.91it/s]\n",
            "2024-04-27:19:39:55,406 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 21223.37it/s]\n",
            "2024-04-27:19:39:56,700 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "100% 62/62 [04:52<00:00,  4.71s/it]\n",
            "2024-04-27:19:45:37,114 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/13617 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 32\n",
            "Running loglikelihood requests: 100% 13617/13617 [06:22<00:00, 35.64it/s] \n",
            "2024-04-27:19:52:15,249 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "Running generate_until requests: 100% 11873/11873 [1:36:21<00:00,  2.05it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/lm_eval/tasks/squadv2/task.py:39: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  squad_metric = datasets.load_metric(\"squad_v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 6.46kB [00:00, 12.0MB/s]       \n",
            "Downloading extra modules: 11.3kB [00:00, 17.7MB/s]       \n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 102411 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 158814 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105896 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168850 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112550 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 133575 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 166056 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 110696 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 107025 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 157414 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 104922 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 134138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105241 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 215901 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 143866 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 141632 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168281 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112735 bytes\n",
            "2024-04-27:21:29:25,145 INFO     [__main__.py:384] Logging to Weights and Biases failed due to 'metric_list'\n",
            "hf (pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (32)\n",
            "| Tasks  |Version|Filter|n-shot|    Metric     | Value |   |Stderr|\n",
            "|--------|------:|------|-----:|---------------|------:|---|------|\n",
            "|wikitext|      2|none  |     0|word_perplexity|26.2506|±  |N/A   |\n",
            "|        |       |none  |     0|byte_perplexity| 1.8424|±  |N/A   |\n",
            "|        |       |none  |     0|bits_per_byte  | 0.8816|±  |N/A   |\n",
            "|sst2    |      1|none  |     0|acc            | 0.6560|±  |0.0161|\n",
            "|squadv2 |      3|none  |     0|exact          | 1.5413|±  |N/A   |\n",
            "|        |       |none  |     0|f1             | 4.6132|±  |N/A   |\n",
            "|        |       |none  |     0|HasAns_exact   | 3.0364|±  |N/A   |\n",
            "|        |       |none  |     0|HasAns_f1      | 9.1889|±  |N/A   |\n",
            "|        |       |none  |     0|NoAns_exact    | 0.0505|±  |N/A   |\n",
            "|        |       |none  |     0|NoAns_f1       | 0.0505|±  |N/A   |\n",
            "|        |       |none  |     0|best_exact     |50.0716|±  |N/A   |\n",
            "|        |       |none  |     0|best_f1        |50.0718|±  |N/A   |\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/HasAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/NoAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       squadv2/best_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          sst2/acc_stderr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/HasAns_exact 3.03644\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/HasAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/HasAns_f1 9.18893\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             squadv2/NoAns_exact 0.05046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/NoAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                squadv2/NoAns_f1 0.05046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   squadv2/alias squadv2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              squadv2/best_exact 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       squadv2/best_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 squadv2/best_f1 50.07182\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   squadv2/exact 1.54131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      squadv2/f1 4.61316\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        sst2/acc 0.65596\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc_stderr 0.0161\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      sst2/alias sst2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  wikitext/alias wikitext\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          wikitext/bits_per_byte 0.88159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/byte_perplexity 1.84241\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/word_perplexity 26.25061\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfallen-sound-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf/runs/0974uqm5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240427_193919-0974uqm5/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-shot"
      ],
      "metadata": {
        "id": "bEVuyTrjVV_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lm_eval --model hf --model_args pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True --tasks squadv2 --device cuda:0 --batch_size 8 --num_fewshot 1 --log_samples --output_path output/mamba-130m-hf-1-shot --wandb_args project=mamba-130m-hf-1-shot"
      ],
      "metadata": {
        "id": "29oVB2t4ZwTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 1 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-130m-hf-1-shot \\\n",
        "    --wandb_args project=mamba-130m-hf-1-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c0cedd-1de5-463f-eadb-21ceb1d59440",
        "id": "-K-Yt7GIVV_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-28 06:14:58.750971: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 06:14:58.751025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 06:14:58.752477: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 06:15:00.010147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 17.8MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240428_061505-rc3r8nno\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-microwave-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf-1-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf-1-shot/runs/rc3r8nno\u001b[0m\n",
            "2024-04-28:06:15:07,035 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-28:06:15:13,219 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-28:06:15:13,219 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-28:06:15:13,227 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-28:06:15:13,311 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 895/895 [00:00<00:00, 2.44MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:01<00:00, 291MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 375kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 11.4MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.09MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 8.17MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 45.9MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.41MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 305524.74 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 236941.64 examples/s]\n",
            "2024-04-28:06:15:32,491 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 1\n",
            "2024-04-28:06:15:32,493 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 18111.40it/s]\n",
            "2024-04-28:06:15:33,905 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "Running generate_until requests:   1% 81/11873 [02:40<4:09:31,  1.27s/it]\n",
            "Running generate_until requests:   1% 88/11873 [02:44<6:08:01,  1.87s/it]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-shot"
      ],
      "metadata": {
        "id": "f7kza1TeWJvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lm_eval --model hf --model_args pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True --tasks squadv2 --device cuda:0 --batch_size auto --num_fewshot 5 --log_samples --output_path output/mamba-130m-hf-5-shot --wandb_args project=mamba-130m-hf-5-shot"
      ],
      "metadata": {
        "id": "uelZPaJoWL9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-130m-hf,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 5 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-130m-hf-5-shot \\\n",
        "    --wandb_args project=mamba-130m-hf-5-shot"
      ],
      "metadata": {
        "id": "4hlmMpi408M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fab23a7-059c-4775-ca01-770557ba0236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-29 13:13:48.730966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-29 13:13:48.731020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-29 13:13:48.732471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-29 13:13:50.051956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 19.5MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240429_131355-j31bve1p\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-mountain-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-130m-hf-5-shot/runs/j31bve1p\u001b[0m\n",
            "2024-04-29:13:13:56,574 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-29:13:14:02,547 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-29:13:14:02,547 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-29:13:14:02,553 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-29:13:14:02,642 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 895/895 [00:00<00:00, 3.28MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:01<00:00, 369MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 343kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 11.2MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.07MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 18.9MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 27.0MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 4.72MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 409000.98 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 418215.17 examples/s]\n",
            "2024-04-29:13:14:21,585 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 5\n",
            "2024-04-29:13:14:21,587 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 12465.99it/s]\n",
            "2024-04-29:13:14:23,296 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 8\n",
            "Running generate_until requests:   7% 841/11873 [20:15<4:02:18,  1.32s/it]\n",
            "Running generate_until requests:   7% 848/11873 [20:22<4:24:48,  1.44s/it]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RWKV-169m"
      ],
      "metadata": {
        "id": "4aqAY06BYxTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0-shot"
      ],
      "metadata": {
        "id": "8pL-ys8aYxTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=RWKV/rwkv-4-169m-pile,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 0 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/rwkv-4-169m-pile \\\n",
        "    --wandb_args project=rwkv-4-169m-pile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9faf2cc-01f7-4c79-e683-b4f9784ec54e",
        "id": "Y6OhrHASYxTE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 21:39:57.948600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 21:39:57.948655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 21:39:57.950136: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 21:39:59.257945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 21.2MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_214004-55f5o7xd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-sponge-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-169m-pile\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-169m-pile/runs/55f5o7xd\u001b[0m\n",
            "2024-04-27:21:40:05,790 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:21:40:11,938 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-27:21:40:11,939 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:21:40:11,944 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:21:40:12,030 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 521/521 [00:00<00:00, 1.78MB/s]\n",
            "pytorch_model.bin: 100% 677M/677M [00:21<00:00, 31.9MB/s]\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 433kB/s]\n",
            "tokenizer_config.json: 100% 264/264 [00:00<00:00, 905kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.11MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 344kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 19.4MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 62.5MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.35MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 428542.59 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 446719.69 examples/s]\n",
            "2024-04-27:21:40:50,943 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 0\n",
            "2024-04-27:21:40:50,944 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 18983.95it/s]\n",
            "2024-04-27:21:40:52,377 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "Running generate_until requests:   1% 145/11873 [03:58<4:11:26,  1.29s/it]\n",
            "Running generate_until requests:   1% 160/11873 [04:10<5:05:56,  1.57s/it]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-4PDnHhR9G7"
      },
      "source": [
        "## Pythia 1.4b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0-shot"
      ],
      "metadata": {
        "id": "U7VGkUlTTi9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32036fb8-6d93-4acd-a827-7cbb557ba61d",
        "id": "qeIDD9-QR9HB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 22:29:34.426815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 22:29:34.426863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 22:29:34.428306: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 22:29:35.619657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 20.3MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_222941-of8vlx10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-dew-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b/runs/of8vlx10\u001b[0m\n",
            "2024-04-27:22:29:42,289 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:22:29:48,315 INFO     [__main__.py:335] Selected Tasks: ['squadv2', 'sst2', 'wikitext']\n",
            "2024-04-27:22:29:48,318 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:22:29:48,326 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:22:29:48,430 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 570/570 [00:00<00:00, 755kB/s]\n",
            "model.safetensors: 100% 2.93G/2.93G [00:21<00:00, 137MB/s] \n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 1.20MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.19MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 305kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 14.7MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 33.5MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.02MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 332046.19 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 219100.75 examples/s]\n",
            "2024-04-27:22:30:28,874 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-27:22:30:28,874 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 448kB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 13.8MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 344kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 693kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 1159472.07 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 348393.32 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 588339.82 examples/s]\n",
            "2024-04-27:22:30:36,590 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:22:30:36,591 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:22:30:36,591 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-27:22:30:36,592 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-27:22:30:36,592 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-27:22:30:36,592 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Downloading builder script: 100% 10.7k/10.7k [00:00<00:00, 17.1MB/s]\n",
            "Downloading readme: 100% 7.78k/7.78k [00:00<00:00, 15.6MB/s]\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-27:22:30:38,955 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "Downloading data: 100% 4.72M/4.72M [00:00<00:00, 72.1MB/s]\n",
            "Generating test split: 62 examples [00:00, 3200.54 examples/s]\n",
            "Generating train split: 629 examples [00:00, 3213.54 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 4154.15 examples/s]\n",
            "2024-04-27:22:30:39,753 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 580.55it/s]\n",
            "2024-04-27:22:30:39,864 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:00<00:00, 2181.71it/s]\n",
            "2024-04-27:22:30:40,288 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 19347.45it/s]\n",
            "2024-04-27:22:30:41,613 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 4\n",
            "100% 62/62 [00:29<00:00,  2.09it/s]\n",
            "2024-04-27:22:31:21,074 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/13617 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 16\n",
            "Running loglikelihood requests: 100% 13617/13617 [02:02<00:00, 111.27it/s]\n",
            "2024-04-27:22:33:41,260 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 4\n",
            "Running generate_until requests:   1% 113/11873 [03:25<4:51:09,  1.49s/it]"
          ]
        }
      ],
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=EleutherAI/pythia-1.4b,trust_remote_code=True \\\n",
        "    --tasks squadv2,sst2,wikitext \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --log_samples \\\n",
        "    --output_path output/pythia-1.4b \\\n",
        "    --wandb_args project=pythia-1.4b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjAdfKXFR9HB"
      },
      "outputs": [],
      "source": [
        "!python lm-evaluation-harness/scripts/zeno_visualize.py --data_path output --project_name \"pythia-1.4b-zeno\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-shot"
      ],
      "metadata": {
        "id": "x8cqAAZpTlej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=EleutherAI/pythia-1.4b,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 5 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/pythia-1.4b-5-shot \\\n",
        "    --wandb_args project=pythia-1.4b-5-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHU08b5yTwSg",
        "outputId": "15ce9565-1a68-4d38-ddb6-234dcf8f6f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 20:47:07.654542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 20:47:07.654603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 20:47:07.656182: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 20:47:08.901015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_204712-378pi95y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-sun-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot/runs/378pi95y\u001b[0m\n",
            "2024-04-27:20:47:13,867 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:20:47:20,766 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-27:20:47:20,766 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:20:47:20,768 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:20:47:20,827 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 570/570 [00:00<00:00, 1.42MB/s]\n",
            "model.safetensors: 100% 2.93G/2.93G [00:19<00:00, 150MB/s]\n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 845kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.18MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 237kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-04-27:20:47:59,746 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 5\n",
            "2024-04-27:20:47:59,748 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 11921.89it/s]\n",
            "2024-04-27:20:48:01,481 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 4\n",
            "Running generate_until requests: 100% 11873/11873 [39:16<00:00,  5.04it/s]\n",
            "2024-04-27:21:27:18,287 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 4\n",
            "Running loglikelihood requests: 100% 11873/11873 [16:52<00:00, 11.73it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/lm_eval/tasks/squadv2/task.py:39: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  squad_metric = datasets.load_metric(\"squad_v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad_v2/squad_v2.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-04-27:21:46:00,180 INFO     [__main__.py:384] Logging to Weights and Biases failed due to 'metric_list'\n",
            "hf (pretrained=EleutherAI/pythia-1.4b,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: auto (4)\n",
            "| Tasks |Version|Filter|n-shot|   Metric   | Value |   |Stderr|\n",
            "|-------|------:|------|-----:|------------|------:|---|------|\n",
            "|squadv2|      3|none  |     5|exact       |13.6865|±  |N/A   |\n",
            "|       |       |none  |     5|f1          |17.5776|±  |N/A   |\n",
            "|       |       |none  |     5|HasAns_exact|27.3954|±  |N/A   |\n",
            "|       |       |none  |     5|HasAns_f1   |35.1888|±  |N/A   |\n",
            "|       |       |none  |     5|NoAns_exact | 0.0168|±  |N/A   |\n",
            "|       |       |none  |     5|NoAns_f1    | 0.0168|±  |N/A   |\n",
            "|       |       |none  |     5|best_exact  |50.0716|±  |N/A   |\n",
            "|       |       |none  |     5|best_f1     |50.0716|±  |N/A   |\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: squadv2/HasAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    squadv2/HasAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  squadv2/NoAns_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/NoAns_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   squadv2/best_exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/best_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/exact ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/HasAns_exact 27.39541\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: squadv2/HasAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/HasAns_f1 35.18882\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    squadv2/HasAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         squadv2/NoAns_exact 0.01682\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  squadv2/NoAns_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            squadv2/NoAns_f1 0.01682\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     squadv2/NoAns_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/alias squadv2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          squadv2/best_exact 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   squadv2/best_exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             squadv2/best_f1 50.07159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      squadv2/best_f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               squadv2/exact 13.68652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        squadv2/exact_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  squadv2/f1 17.57764\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           squadv2/f1_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlikely-sun-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot/runs/378pi95y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240427_204712-378pi95y/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua1GTEN6AEHq"
      },
      "source": [
        "## RWKV 1.5b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=RWKV/rwkv-4-1b5-pile,trust_remote_code=True \\\n",
        "    --tasks sst2,wikitext \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 5 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/rwkv-4-1b5-pile-5-shot \\\n",
        "    --wandb_args project=rwkv-4-1b5-pile-5-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6R_IAWdjsh",
        "outputId": "c4a52e3c-f177-4012-fcca-023286173d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 02:06:09.258814: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 02:06:09.258863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 02:06:09.260362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 02:06:10.586473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240422_020616-bhp7kx1i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcerulean-wave-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile-5-shot/runs/bhp7kx1i\u001b[0m\n",
            "2024-04-22:02:06:17,850 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-22:02:06:25,190 INFO     [__main__.py:335] Selected Tasks: ['sst2', 'wikitext']\n",
            "2024-04-22:02:06:25,191 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-22:02:06:25,197 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-22:02:06:25,261 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-04-22:02:06:44,512 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-22:02:06:44,512 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "2024-04-22:02:06:53,109 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-22:02:06:53,109 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-22:02:06:53,109 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-22:02:06:53,109 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-22:02:06:53,110 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-22:02:06:53,110 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-22:02:06:56,091 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-22:02:06:56,141 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 5\n",
            "2024-04-22:02:06:56,141 WARNING  [evaluator.py:222] Overwriting default num_fewshot of sst2 from None to 5\n",
            "2024-04-22:02:06:56,145 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 63.40it/s]\n",
            "2024-04-22:02:06:57,128 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:04<00:00, 213.55it/s]\n",
            "2024-04-22:02:07:01,245 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "100% 62/62 [08:04<00:00,  7.82s/it]\n",
            "2024-04-22:02:16:16,594 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/1744 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 32\n",
            "Running loglikelihood requests: 100% 1744/1744 [01:35<00:00, 18.21it/s]\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 102411 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 158814 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105896 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168850 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112550 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 133575 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 166056 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 110696 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 107025 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 157414 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 104922 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 134138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105241 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 215901 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 143866 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 141632 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168281 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112735 bytes\n",
            "hf (pretrained=RWKV/rwkv-4-1b5-pile,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: auto (32)\n",
            "| Tasks  |Version|Filter|n-shot|    Metric     | Value |   |Stderr|\n",
            "|--------|------:|------|-----:|---------------|------:|---|------|\n",
            "|wikitext|      2|none  |     5|word_perplexity|16.1771|±  |N/A   |\n",
            "|        |       |none  |     5|byte_perplexity| 1.6829|±  |N/A   |\n",
            "|        |       |none  |     5|bits_per_byte  | 0.7510|±  |N/A   |\n",
            "|sst2    |      1|none  |     5|acc            | 0.6468|±  |0.0162|\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          sst2/acc_stderr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        sst2/acc 0.64679\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc_stderr 0.0162\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      sst2/alias sst2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  wikitext/alias wikitext\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          wikitext/bits_per_byte 0.75099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/byte_perplexity 1.68295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/word_perplexity 16.17712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcerulean-wave-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile-5-shot/runs/bhp7kx1i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 4 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240422_020616-bhp7kx1i/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wugwWCs8AEH2",
        "outputId": "f2d64c27-5b8a-476d-8485-8fc1f855111b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-21 23:43:13.257265: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-21 23:43:13.257316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-21 23:43:13.258714: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-21 23:43:14.518674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 18.7MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240421_234319-hi2sfy2v\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgraceful-jazz-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/rwkv-4-1b5-pile/runs/hi2sfy2v\u001b[0m\n",
            "2024-04-21:23:43:21,169 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-21:23:43:27,551 INFO     [__main__.py:335] Selected Tasks: ['squadv2', 'sst2', 'wikitext']\n",
            "2024-04-21:23:43:27,551 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-21:23:43:27,560 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-21:23:43:27,646 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 522/522 [00:00<00:00, 1.08MB/s]\n",
            "pytorch_model.bin: 100% 6.06G/6.06G [03:29<00:00, 28.9MB/s]\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 270kB/s]\n",
            "tokenizer_config.json: 100% 264/264 [00:00<00:00, 604kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.98MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 126kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 8.92k/8.92k [00:00<00:00, 13.8MB/s]\n",
            "Downloading data: 100% 16.4M/16.4M [00:00<00:00, 31.0MB/s]\n",
            "Downloading data: 100% 1.35M/1.35M [00:00<00:00, 6.26MB/s]\n",
            "Generating train split: 100% 130319/130319 [00:00<00:00, 251506.24 examples/s]\n",
            "Generating validation split: 100% 11873/11873 [00:00<00:00, 183720.72 examples/s]\n",
            "2024-04-21:23:47:41,425 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-21:23:47:41,425 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 30.2MB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 7.28MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 311kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 370kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 823368.77 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 205439.14 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 336987.76 examples/s]\n",
            "2024-04-21:23:47:51,296 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-21:23:47:51,297 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-21:23:47:51,297 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-21:23:47:51,297 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-21:23:47:51,298 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-21:23:47:51,298 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Downloading builder script: 100% 10.7k/10.7k [00:00<00:00, 13.7MB/s]\n",
            "Downloading readme: 100% 7.78k/7.78k [00:00<00:00, 10.9MB/s]\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-21:23:47:53,469 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "Downloading data: 100% 4.72M/4.72M [00:00<00:00, 71.2MB/s]\n",
            "Generating test split: 62 examples [00:00, 2177.97 examples/s]\n",
            "Generating train split: 629 examples [00:00, 3032.05 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 3381.59 examples/s]\n",
            "2024-04-21:23:47:54,331 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 524.63it/s]\n",
            "2024-04-21:23:47:54,453 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:00<00:00, 2024.51it/s]\n",
            "2024-04-21:23:47:54,912 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 18108.81it/s]\n",
            "2024-04-21:23:47:56,355 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "100% 62/62 [08:07<00:00,  7.87s/it]\n",
            "2024-04-21:23:57:17,367 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/13617 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 16\n",
            "Running loglikelihood requests: 100% 13617/13617 [24:29<00:00,  9.27it/s] \n",
            "2024-04-22:00:22:05,157 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 16\n",
            "Running generate_until requests:   4% 529/11873 [25:50<8:25:45,  2.68s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 775, in generate\n",
            "    gen_output = super().generate(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1576, in generate\n",
            "    result = self._greedy_search(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2494, in _greedy_search\n",
            "    outputs = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 828, in forward\n",
            "    rwkv_outputs = self.rwkv(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 668, in forward\n",
            "    hidden_states, state, attentions = block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 374, in forward\n",
            "    attention, state = self.attention(self.ln1(hidden), state=state, use_cache=use_cache)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 300, in forward\n",
            "    rwkv, layer_state = rwkv_linear_attention(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 242, in rwkv_linear_attention\n",
            "    return rwkv_linear_attention_cpu(time_decay, time_first, key, value, state=state, return_state=return_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 220, in rwkv_linear_attention_cpu\n",
            "    output[:, current_index] = (numerator / denominator).to(output.dtype)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 234, in simple_evaluate\n",
            "    results = evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/evaluator.py\", line 373, in evaluate\n",
            "    resps = getattr(lm, reqtype)(cloned_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 1196, in generate_until\n",
            "    cont = self._model_generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lm_eval/models/huggingface.py\", line 768, in _model_generate\n",
            "    return self.model.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/rwkv/modeling_rwkv.py\", line 775, in generate\n",
            "    gen_output = super().generate(*args, **kwargs)\n",
            "KeyboardInterrupt\n",
            "Running generate_until requests:   5% 544/11873 [26:21<9:09:02,  2.91s/it]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# !lm_eval \\\n",
        "#     --model hf \\\n",
        "#     --model_args pretrained=RWKV/rwkv-4-1b5-pile,trust_remote_code=True \\\n",
        "#     --tasks squadv2,sst2,wikitext \\\n",
        "#     --device cuda:0 \\\n",
        "#     --batch_size auto \\\n",
        "#     --log_samples \\\n",
        "#     --output_path output/rwkv-4-1b5-pile \\\n",
        "#     --wandb_args project=rwkv-4-1b5-pile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zdipD6ZAEH2"
      },
      "outputs": [],
      "source": [
        "!python lm-evaluation-harness/scripts/zeno_visualize.py --data_path output --project_name \"rwkv-1.5b-zeno\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX1LoD8GZ4de"
      },
      "source": [
        "## Mamba 1.4b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0-shot"
      ],
      "metadata": {
        "id": "MLze4BtGZ4df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SST2,WikiText2"
      ],
      "metadata": {
        "id": "-vnnu4d8QwsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf,trust_remote_code=True \\\n",
        "    --tasks sst2,wikitext \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-1.4b-hf \\\n",
        "    --wandb_args project=mamba-1.4b-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAnNdLK9Q159",
        "outputId": "5e34c6a4-3561-480a-da09-1661a2e0913c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-29 19:16:08.965177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-29 19:16:08.965242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-29 19:16:08.966698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-29 19:16:10.209488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 18.0MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240429_191615-cg04saoi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msolar-vortex-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf/runs/cg04saoi\u001b[0m\n",
            "2024-04-29:19:16:16,449 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-29:19:16:22,317 INFO     [__main__.py:335] Selected Tasks: ['sst2', 'wikitext']\n",
            "2024-04-29:19:16:22,317 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-29:19:16:22,323 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-29:19:16:22,404 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 879/879 [00:00<00:00, 3.35MB/s]\n",
            "model.safetensors.index.json: 100% 38.2k/38.2k [00:00<00:00, 59.7MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.96G [00:00<00:17, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.96G [00:00<00:14, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.96G [00:00<00:13, 357MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.96G [00:00<00:13, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.96G [00:00<00:12, 376MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.96G [00:00<00:12, 386MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.96G [00:00<00:11, 392MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.96G [00:00<00:11, 388MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.96G [00:00<00:11, 393MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.96G [00:01<00:11, 396MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.96G [00:01<00:11, 398MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.96G [00:01<00:11, 397MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.96G [00:01<00:11, 398MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.96G [00:01<00:11, 395MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.96G [00:01<00:11, 393MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.96G [00:01<00:11, 389MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.96G [00:01<00:10, 390MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.96G [00:01<00:10, 389MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.96G [00:02<00:10, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.96G [00:02<00:11, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.96G [00:02<00:11, 349MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.96G [00:02<00:11, 359MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.96G [00:02<00:10, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.96G [00:02<00:10, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.96G [00:02<00:10, 366MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.96G [00:02<00:10, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.96G [00:02<00:10, 363MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.96G [00:03<00:10, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.96G [00:03<00:09, 378MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.96G [00:03<00:09, 379MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.96G [00:03<00:09, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.96G [00:03<00:09, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.96G [00:03<00:09, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.96G [00:03<00:09, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.96G [00:03<00:09, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.96G [00:03<00:09, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.96G [00:04<00:09, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.96G [00:04<00:09, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.96G [00:04<00:09, 345MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.96G [00:04<00:09, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.96G [00:04<00:09, 353MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.96G [00:04<00:09, 345MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.96G [00:04<00:09, 349MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.96G [00:04<00:08, 361MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.96G [00:05<00:08, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.96G [00:05<00:08, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.96G/4.96G [00:05<00:08, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.96G [00:05<00:08, 346MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.96G [00:05<00:09, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.96G [00:05<00:09, 311MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.96G [00:05<00:08, 318MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.96G [00:05<00:08, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.96G [00:06<00:08, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.96G [00:06<00:08, 329MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.96G [00:06<00:08, 331MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.96G [00:06<00:07, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.96G [00:06<00:08, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.96G [00:06<00:07, 326MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.96G [00:06<00:08, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.96G [00:07<00:08, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.96G [00:07<00:07, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.96G [00:07<00:07, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.96G [00:07<00:07, 325MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.96G [00:07<00:06, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.71G/4.96G [00:07<00:06, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.96G [00:07<00:06, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.96G [00:07<00:06, 357MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.96G [00:07<00:05, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.96G [00:08<00:05, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.96G [00:08<00:05, 380MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.96G [00:08<00:05, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.96G [00:08<00:05, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.96G [00:08<00:05, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:08<00:04, 378MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.96G [00:08<00:04, 375MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.96G [00:08<00:04, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.96G [00:08<00:04, 370MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.25G/4.96G [00:09<00:04, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.96G [00:09<00:04, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.96G [00:09<00:04, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.96G [00:09<00:04, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.96G [00:09<00:04, 363MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.96G [00:09<00:04, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.96G [00:09<00:04, 358MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.96G [00:09<00:04, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.96G [00:10<00:04, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.96G [00:10<00:03, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.96G [00:10<00:03, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.96G [00:10<00:03, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.96G [00:10<00:03, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.80G/4.96G [00:10<00:03, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.96G [00:10<00:03, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.96G [00:10<00:03, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.96G [00:11<00:03, 313MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.96G [00:11<00:03, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.96G [00:11<00:03, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.96G [00:11<00:03, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.96G [00:11<00:02, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.96G [00:11<00:02, 329MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.96G [00:11<00:02, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.96G [00:11<00:02, 360MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.96G [00:11<00:01, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.96G [00:12<00:01, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.96G [00:12<00:01, 379MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.96G [00:12<00:01, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.39G/4.96G [00:12<00:01, 389MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.96G [00:12<00:01, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.96G [00:12<00:01, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.96G [00:12<00:01, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.96G [00:12<00:01, 391MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.96G [00:12<00:00, 395MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.96G [00:13<00:00, 399MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.96G [00:13<00:00, 395MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.96G [00:13<00:00, 388MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.96G [00:13<00:00, 383MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.96G [00:13<00:00, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.96G [00:13<00:00, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.96G [00:13<00:00, 379MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:13<00:00, 356MB/s]\n",
            "Downloading shards:  50% 1/2 [00:14<00:14, 14.32s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 10.5M/528M [00:00<00:11, 45.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 41.9M/528M [00:00<00:03, 148MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 83.9M/528M [00:00<00:02, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 115M/528M [00:00<00:01, 215MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 147M/528M [00:00<00:01, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 189M/528M [00:00<00:01, 266MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 220M/528M [00:00<00:01, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 252M/528M [00:01<00:00, 277MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 283M/528M [00:01<00:00, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 315M/528M [00:01<00:00, 286MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 346M/528M [00:01<00:00, 293MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 377M/528M [00:01<00:00, 293MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 409M/528M [00:01<00:00, 265MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 451M/528M [00:01<00:00, 282MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 493M/528M [00:01<00:00, 299MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:01<00:00, 264MB/s]\n",
            "Downloading shards: 100% 2/2 [00:16<00:00,  8.29s/it]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 353kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 10.4MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.11MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-04-29:19:16:44,150 WARNING  [task.py:763] [Task: sst2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-04-29:19:16:44,151 WARNING  [task.py:775] [Task: sst2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 443kB/s]\n",
            "Downloading data: 100% 3.11M/3.11M [00:00<00:00, 9.56MB/s]\n",
            "Downloading data: 100% 72.8k/72.8k [00:00<00:00, 335kB/s]\n",
            "Downloading data: 100% 148k/148k [00:00<00:00, 683kB/s]\n",
            "Generating train split: 100% 67349/67349 [00:00<00:00, 890195.51 examples/s]\n",
            "Generating validation split: 100% 872/872 [00:00<00:00, 348459.71 examples/s]\n",
            "Generating test split: 100% 1821/1821 [00:00<00:00, 518416.32 examples/s]\n",
            "2024-04-29:19:16:56,325 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-29:19:16:56,325 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-29:19:16:56,325 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
            "2024-04-29:19:16:56,326 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "2024-04-29:19:16:56,326 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
            "2024-04-29:19:16:56,326 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
            "Downloading builder script: 100% 10.7k/10.7k [00:00<00:00, 23.0MB/s]\n",
            "Downloading readme: 100% 7.78k/7.78k [00:00<00:00, 15.4MB/s]\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "2024-04-29:19:16:58,296 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
            "Downloading data: 100% 4.72M/4.72M [00:01<00:00, 4.43MB/s]\n",
            "Generating test split: 62 examples [00:00, 2995.17 examples/s]\n",
            "Generating train split: 629 examples [00:00, 3175.58 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 4162.81 examples/s]\n",
            "2024-04-29:19:17:00,473 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
            "100% 62/62 [00:00<00:00, 559.91it/s]\n",
            "2024-04-29:19:17:00,588 INFO     [task.py:395] Building contexts for sst2 on rank 0...\n",
            "100% 872/872 [00:00<00:00, 2053.85it/s]\n",
            "2024-04-29:19:17:01,040 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
            "Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 2\n",
            "100% 62/62 [15:22<00:00, 14.88s/it]\n",
            "2024-04-29:19:33:28,444 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0% 0/1744 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
            "Determined largest batch size: 64\n",
            "Running loglikelihood requests: 100% 1744/1744 [00:31<00:00, 55.25it/s] \n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 102411 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 158814 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105896 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168850 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112550 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 133575 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 166056 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 110696 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 107025 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 157414 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 104922 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 134138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105241 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 215901 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 143866 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 141632 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 168281 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112138 bytes\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 112735 bytes\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)\n",
            "| Tasks  |Version|Filter|n-shot|    Metric     | Value |   |Stderr|\n",
            "|--------|------:|------|-----:|---------------|------:|---|------|\n",
            "|wikitext|      2|none  |     0|word_perplexity|13.5659|±  |N/A   |\n",
            "|        |       |none  |     0|byte_perplexity| 1.6284|±  |N/A   |\n",
            "|        |       |none  |     0|bits_per_byte  | 0.7035|±  |N/A   |\n",
            "|sst2    |      1|none  |     0|acc            | 0.4989|±  |0.0169|\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          sst2/acc_stderr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        sst2/acc 0.49885\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 sst2/acc_stderr 0.01694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      sst2/alias sst2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  wikitext/alias wikitext\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          wikitext/bits_per_byte 0.7035\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   wikitext/bits_per_byte_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/byte_perplexity 1.62845\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/byte_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        wikitext/word_perplexity 13.56588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wikitext/word_perplexity_stderr N/A\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msolar-vortex-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf/runs/cg04saoi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 6 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240429_191615-cg04saoi/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SQuADv2"
      ],
      "metadata": {
        "id": "hW1_J7c-QqBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3312687e-f6a0-4697-ac9d-a4d718dec269",
        "id": "qdUq8On1Z4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 21:51:23.957856: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 21:51:23.957911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 21:51:23.959233: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 21:51:25.213562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_215129-ynesrsy5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdistinctive-frog-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/mamba-1.4b-hf/runs/ynesrsy5\u001b[0m\n",
            "2024-04-27:21:51:30,780 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:21:51:36,581 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-27:21:51:36,581 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:21:51:36,583 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:21:51:36,640 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.96G [00:00<05:48, 14.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.96G [00:00<03:15, 25.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.96G [00:01<02:24, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.96G [00:01<02:00, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.96G [00:01<01:47, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.96G [00:01<01:40, 48.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.96G [00:01<01:35, 51.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.96G [00:02<01:32, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.96G [00:02<01:29, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.96G [00:02<01:28, 55.1MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.96G [00:02<01:27, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.96G [00:02<01:26, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.96G [00:02<01:25, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.96G [00:03<01:25, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.96G [00:03<01:24, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.96G [00:03<01:24, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.96G [00:03<01:23, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.96G [00:03<01:23, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.96G [00:04<01:23, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.96G [00:04<01:23, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.96G [00:04<01:23, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.96G [00:04<01:22, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.96G [00:04<01:22, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.96G [00:04<01:22, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.96G [00:05<01:22, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.96G [00:05<01:22, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.96G [00:05<01:21, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.96G [00:05<01:26, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.96G [00:05<01:25, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.96G [00:06<01:24, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.96G [00:06<01:23, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.96G [00:06<01:22, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.96G [00:06<01:22, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.96G [00:06<01:21, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.96G [00:07<01:21, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.96G [00:07<01:21, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.96G [00:07<01:20, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.96G [00:07<01:20, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.96G [00:07<01:20, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.96G [00:07<01:20, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.96G [00:08<01:19, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.96G [00:08<01:19, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.96G [00:08<01:19, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.96G [00:08<01:18, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.96G [00:08<01:18, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.96G [00:09<01:18, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.96G [00:09<01:23, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.96G [00:09<01:21, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.96G [00:09<01:20, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.96G [00:09<01:19, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.96G [00:10<01:19, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.96G [00:10<01:23, 52.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.96G [00:10<01:23, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.96G [00:10<01:14, 58.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.96G [00:10<01:15, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.96G [00:10<01:16, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.96G [00:11<01:15, 57.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.96G [00:11<01:15, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.96G [00:11<01:15, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.96G [00:11<01:16, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.96G [00:11<01:16, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.96G [00:12<01:15, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.96G [00:12<01:15, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.96G [00:12<01:15, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.96G [00:12<01:15, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.96G [00:12<01:15, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.96G [00:12<01:14, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.96G [00:13<01:14, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.96G [00:13<01:15, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.96G [00:13<01:14, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.96G [00:13<01:14, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.96G [00:13<01:14, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.96G [00:14<01:13, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.96G [00:14<01:13, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.96G [00:14<01:13, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.96G [00:14<01:12, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.96G [00:14<01:14, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.96G [00:15<01:14, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.96G [00:15<01:13, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.96G [00:15<01:12, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.96G [00:15<01:12, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.96G [00:15<01:12, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.96G [00:15<01:11, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.96G [00:16<01:12, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.96G [00:16<01:12, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.96G [00:16<01:11, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.96G [00:16<01:12, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.96G [00:16<01:12, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.96G [00:17<01:11, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.96G [00:17<01:11, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.96G [00:17<01:10, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.96G [00:17<01:10, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.96G [00:17<01:10, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.96G [00:17<01:09, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.96G [00:18<01:09, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.96G [00:18<01:09, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.02G/4.96G [00:18<01:10, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.96G [00:18<01:09, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.96G [00:18<01:09, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.96G [00:19<01:09, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.96G [00:19<01:08, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.96G [00:19<01:08, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.96G [00:19<01:08, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.96G [00:19<01:07, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.96G [00:20<01:07, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.96G [00:20<01:07, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.96G [00:20<01:08, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.96G [00:20<01:07, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.96G [00:20<01:07, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.96G [00:20<01:07, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.96G [00:21<01:07, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.96G [00:21<01:11, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.96G [00:21<01:07, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.96G [00:21<01:05, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.96G [00:21<01:07, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.22G/4.96G [00:22<01:03, 58.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.96G [00:22<01:04, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.96G [00:22<01:04, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.96G [00:22<01:05, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.96G [00:22<01:05, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.96G [00:22<01:05, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.96G [00:23<01:05, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.96G [00:23<01:05, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.96G [00:23<01:04, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.96G [00:23<01:04, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.96G [00:23<01:04, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.96G [00:24<01:04, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.96G [00:24<01:31, 39.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.96G [00:24<01:16, 46.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.96G [00:24<01:15, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.96G [00:25<01:11, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.96G [00:25<01:10, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.96G [00:25<01:07, 52.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.96G [00:25<01:06, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.96G [00:25<01:05, 53.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.96G [00:26<01:04, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.96G [00:26<01:03, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.96G [00:26<01:02, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.96G [00:26<01:02, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.96G [00:26<01:01, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.96G [00:26<01:01, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.96G [00:27<01:01, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.96G [00:27<01:01, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.96G [00:27<01:00, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.96G [00:27<01:00, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.96G [00:27<01:00, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.96G [00:28<00:59, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.96G [00:28<00:59, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.96G [00:28<00:59, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.96G [00:28<00:59, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.96G [00:28<00:59, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.96G [00:28<00:58, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.96G [00:29<00:58, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.96G [00:29<00:58, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.96G [00:29<00:59, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.96G [00:29<00:59, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.96G [00:29<00:58, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.96G [00:30<00:58, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.96G [00:30<00:57, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.96G [00:30<00:57, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.96G [00:30<00:58, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.96G [00:30<00:57, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.96G [00:31<00:57, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.96G [00:31<00:57, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.96G [00:31<00:58, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.96G [00:31<00:57, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.96G [00:31<00:57, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.76G/4.96G [00:31<00:57, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.96G [00:32<00:56, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.96G [00:32<00:56, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.96G [00:32<00:57, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.96G [00:32<00:55, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.96G [00:32<01:01, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.96G [00:33<00:53, 58.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.96G [00:33<00:53, 58.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.96G [00:33<00:53, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.96G [00:33<00:53, 57.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.96G [00:33<00:54, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.96G [00:33<00:53, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.96G [00:34<00:53, 57.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.96G [00:34<00:53, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.96G [00:34<00:53, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.96G [00:34<00:53, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.96G [00:34<00:53, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.96G [00:35<00:53, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.96G [00:35<00:53, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.96G/4.96G [00:35<00:52, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.96G [00:35<00:52, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.96G [00:35<00:52, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.96G [00:36<00:52, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.96G [00:36<00:52, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.96G [00:36<00:51, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.96G [00:36<00:51, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.96G [00:36<00:51, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.96G [00:36<00:51, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.96G [00:37<00:51, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.96G [00:37<00:51, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.96G [00:37<00:51, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.96G [00:37<00:50, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.96G [00:37<00:50, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.96G [00:38<00:50, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.96G [00:38<00:50, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.96G [00:38<00:50, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.96G [00:38<00:49, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.96G [00:38<00:50, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.16G/4.96G [00:38<00:49, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.96G [00:39<00:49, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.96G [00:39<00:49, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.96G [00:39<00:49, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.96G [00:39<00:48, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.96G [00:39<00:48, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.96G [00:40<00:48, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.96G [00:40<00:48, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.96G [00:40<00:47, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.96G [00:40<00:47, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.96G [00:40<00:47, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.96G [00:41<00:47, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.96G [00:41<00:46, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.96G [00:41<00:46, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.31G/4.96G [00:41<00:46, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.96G [00:41<00:46, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.96G [00:41<00:46, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.96G [00:42<00:46, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.96G [00:42<00:46, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.96G [00:42<00:46, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.96G [00:42<00:45, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.96G [00:42<00:45, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.96G [00:43<00:46, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.96G [00:43<00:45, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.96G [00:43<00:46, 54.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.96G [00:43<00:44, 57.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.96G [00:43<00:46, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.96G [00:43<00:43, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.96G [00:44<00:43, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.96G [00:44<00:43, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.96G [00:44<00:43, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.96G [00:44<00:43, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.96G [00:44<00:43, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.51G/4.96G [00:45<00:43, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.96G [00:45<00:42, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.96G [00:45<00:42, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.96G [00:45<00:42, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.96G [00:45<00:42, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.96G [00:46<00:42, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.96G [00:46<00:42, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.96G [00:46<00:42, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.96G [00:46<00:42, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.96G [00:46<00:41, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.96G [00:46<00:41, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.96G [00:47<00:41, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.96G [00:47<00:41, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.96G [00:47<00:40, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.96G [00:47<00:40, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.96G [00:47<00:40, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.96G [00:48<00:40, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.96G [00:48<00:40, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.96G [00:48<00:39, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.71G/4.96G [00:48<00:40, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.96G [00:48<00:40, 54.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.96G [00:48<00:39, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.96G [00:49<00:38, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.96G [00:49<00:38, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.96G [00:49<00:38, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.96G [00:49<00:38, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.96G [00:49<00:38, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.96G [00:50<00:38, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.96G [00:50<00:38, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.96G [00:50<00:37, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.96G [00:50<00:37, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.96G [00:50<00:38, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.96G [00:51<00:38, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.96G [00:51<00:37, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.96G [00:51<00:37, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.96G [00:51<00:36, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.96G [00:51<00:36, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.96G [00:51<00:36, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.90G/4.96G [00:52<00:36, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.96G [00:52<00:35, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.96G [00:52<00:35, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.96G [00:52<00:35, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.96G [00:52<00:35, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.96G [00:53<00:35, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.96G [00:53<00:34, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.96G [00:53<00:34, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.96G [00:53<00:34, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.96G [00:53<00:35, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.96G [00:54<00:35, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.96G [00:54<00:33, 58.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.96G [00:54<00:35, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.96G [00:54<00:34, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.05G/4.96G [00:54<00:32, 58.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.96G [00:54<00:32, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.96G [00:55<00:32, 57.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:55<00:32, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.96G [00:55<00:32, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.96G [00:55<00:32, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.96G [00:55<00:32, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.96G [00:56<00:32, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.96G [00:56<00:32, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.96G [00:56<00:32, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.96G [00:56<00:31, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.96G [00:56<00:31, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.96G [00:56<00:31, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.96G [00:57<00:31, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.96G [00:57<00:31, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.96G [00:57<00:30, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.96G [00:57<00:30, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.96G [00:57<00:30, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.96G [00:58<00:30, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.25G/4.96G [00:58<00:30, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.96G [00:58<00:29, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.96G [00:58<00:29, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.96G [00:58<00:29, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.96G [00:58<00:29, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.96G [00:59<00:29, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.96G [00:59<00:29, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.96G [00:59<00:28, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.96G [00:59<00:28, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.96G [00:59<00:28, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.96G [01:00<00:28, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.96G [01:00<00:28, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.96G [01:00<00:27, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.96G [01:00<00:27, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.96G [01:00<00:27, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.96G [01:01<00:27, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.96G [01:01<00:27, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.96G [01:01<00:26, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.96G [01:01<00:26, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.45G/4.96G [01:01<00:26, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.96G [01:01<00:26, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.96G [01:02<00:26, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.96G [01:02<00:26, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.96G [01:02<00:25, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.96G [01:02<00:25, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.96G [01:02<00:25, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.96G [01:03<00:25, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.96G [01:03<00:25, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.96G [01:03<00:25, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.96G [01:03<00:24, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.96G [01:03<00:24, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.96G [01:03<00:24, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.96G [01:04<00:24, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.60G/4.96G [01:04<00:24, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.96G [01:04<00:23, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.96G [01:04<00:23, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.96G [01:04<00:25, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.96G [01:05<00:23, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.65G/4.96G [01:05<00:23, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.96G [01:05<00:22, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.96G [01:05<00:22, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.96G [01:05<00:22, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.96G [01:06<00:22, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.96G [01:06<00:24, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.96G [01:06<00:21, 59.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.96G [01:06<00:21, 58.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.96G [01:06<00:21, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.96G [01:06<00:21, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.96G [01:07<00:21, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.96G [01:07<00:20, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.96G [01:07<00:20, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.96G [01:07<00:20, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.80G/4.96G [01:07<00:20, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.96G [01:08<00:20, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.96G [01:08<00:20, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.96G [01:08<00:20, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.96G [01:08<00:19, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.85G/4.96G [01:08<00:19, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.86G/4.96G [01:08<00:19, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.96G [01:09<00:19, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.96G [01:09<00:19, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.96G [01:09<00:18, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.90G/4.96G [01:09<00:18, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.96G [01:09<00:18, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.96G [01:10<00:18, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.96G [01:10<00:18, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.96G [01:10<00:17, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.96G [01:10<00:17, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.96G [01:10<00:17, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.96G [01:11<00:17, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.96G [01:11<00:17, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.00G/4.96G [01:11<00:17, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.96G [01:11<00:17, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.96G [01:11<00:16, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.96G [01:11<00:16, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.96G [01:12<00:16, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.96G [01:12<00:16, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.96G [01:12<00:15, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.96G [01:12<00:15, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.96G [01:12<00:15, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.96G [01:13<00:15, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.96G [01:13<00:15, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.96G [01:13<00:14, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.96G [01:13<00:14, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.96G [01:13<00:14, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.96G [01:13<00:14, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.96G [01:14<00:14, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.96G [01:14<00:14, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.96G [01:14<00:13, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.96G [01:14<00:13, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.19G/4.96G [01:14<00:13, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.96G [01:15<00:13, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.96G [01:15<00:13, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.96G [01:15<00:13, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.96G [01:15<00:12, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.96G [01:15<00:12, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.26G/4.96G [01:16<00:13, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.96G [01:16<00:11, 58.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.96G [01:16<00:12, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.96G [01:16<00:11, 58.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.96G [01:16<00:11, 57.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.96G [01:16<00:11, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.96G [01:17<00:11, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.96G [01:17<00:11, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.34G/4.96G [01:17<00:11, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.96G [01:17<00:10, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.96G [01:17<00:10, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.96G [01:18<00:10, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.96G [01:18<00:10, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.39G/4.96G [01:18<00:10, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.96G [01:18<00:09, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.96G [01:18<00:09, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.96G [01:19<00:09, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.96G [01:19<00:09, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.96G [01:19<00:09, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.96G [01:19<00:09, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.96G [01:19<00:08, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.96G [01:19<00:08, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.96G [01:20<00:08, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.96G [01:20<00:08, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.96G [01:20<00:07, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.96G [01:20<00:07, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.96G [01:20<00:07, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.54G/4.96G [01:21<00:07, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.96G [01:21<00:07, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.96G [01:21<00:07, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.96G [01:21<00:06, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.96G [01:21<00:06, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.59G/4.96G [01:22<00:06, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.96G [01:22<00:06, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.96G [01:22<00:06, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.96G [01:22<00:05, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.96G [01:22<00:05, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.96G [01:22<00:05, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.96G [01:23<00:05, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.96G [01:23<00:05, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.96G [01:23<00:05, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.96G [01:23<00:04, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.96G [01:23<00:04, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.96G [01:24<00:04, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.96G [01:24<00:04, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.96G [01:24<00:04, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.74G/4.96G [01:24<00:03, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.96G [01:24<00:03, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.96G [01:25<00:03, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.96G [01:25<00:03, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.96G [01:25<00:03, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.79G/4.96G [01:25<00:02, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.80G/4.96G [01:25<00:02, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.96G [01:25<00:02, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.96G [01:26<00:02, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.96G [01:26<00:02, 56.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.84G/4.96G [01:26<00:02, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.96G [01:26<00:01, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.96G [01:26<00:01, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.96G [01:27<00:01, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.89G/4.96G [01:27<00:01, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.96G [01:27<00:01, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.96G [01:27<00:00, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.96G [01:27<00:00, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.96G [01:28<00:00, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.94G/4.96G [01:28<00:00, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.96G [01:28<00:00, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [01:28<00:00, 56.0MB/s]\n",
            "Downloading shards:  50% 1/2 [01:28<01:28, 88.91s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 31.5M/528M [00:00<00:01, 312MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 73.4M/528M [00:00<00:01, 332MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 115M/528M [00:00<00:01, 252MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 147M/528M [00:00<00:01, 255MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 178M/528M [00:00<00:01, 258MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 210M/528M [00:00<00:01, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 241M/528M [00:00<00:01, 255MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 273M/528M [00:01<00:00, 265MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 304M/528M [00:01<00:00, 265MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 336M/528M [00:01<00:00, 271MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 367M/528M [00:01<00:00, 267MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 398M/528M [00:01<00:00, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 430M/528M [00:01<00:00, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 461M/528M [00:01<00:00, 263MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 493M/528M [00:01<00:00, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:02<00:00, 259MB/s]\n",
            "Downloading shards: 100% 2/2 [01:31<00:00, 45.61s/it]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.63s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 333kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 10.4MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 6.48MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-04-27:21:53:47,191 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 18809.06it/s]\n",
            "2024-04-27:21:53:48,533 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 2\n",
            "Running generate_until requests:   1% 65/11873 [09:28<22:52:45,  6.98s/it]"
          ]
        }
      ],
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-1.4b-hf \\\n",
        "    --wandb_args project=mamba-1.4b-hf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-shot"
      ],
      "metadata": {
        "id": "zjFv6cbyZ4df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval \\\n",
        "    --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf,trust_remote_code=True \\\n",
        "    --tasks squadv2 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size auto \\\n",
        "    --num_fewshot 5 \\\n",
        "    --log_samples \\\n",
        "    --output_path output/mamba-1.4b-hf-5-shot \\\n",
        "    --wandb_args project=mamba-1.4b-hf-5-shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ce9565-1a68-4d38-ddb6-234dcf8f6f1e",
        "id": "E7LacHm4Z4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 20:47:07.654542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 20:47:07.654603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 20:47:07.656182: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 20:47:08.901015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk-kiron\u001b[0m (\u001b[33mift6135\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240427_204712-378pi95y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-sun-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ift6135/pythia-1.4b-5-shot/runs/378pi95y\u001b[0m\n",
            "2024-04-27:20:47:13,867 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-04-27:20:47:20,766 INFO     [__main__.py:335] Selected Tasks: ['squadv2']\n",
            "2024-04-27:20:47:20,766 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-04-27:20:47:20,768 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-04-27:20:47:20,827 INFO     [huggingface.py:162] Using device 'cuda:0'\n",
            "config.json: 100% 570/570 [00:00<00:00, 1.42MB/s]\n",
            "model.safetensors: 100% 2.93G/2.93G [00:19<00:00, 150MB/s]\n",
            "tokenizer_config.json: 100% 396/396 [00:00<00:00, 845kB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.18MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 237kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-04-27:20:47:59,746 WARNING  [evaluator.py:222] Overwriting default num_fewshot of squadv2 from None to 5\n",
            "2024-04-27:20:47:59,748 INFO     [task.py:395] Building contexts for None on rank 0...\n",
            "100% 11873/11873 [00:00<00:00, 11921.89it/s]\n",
            "2024-04-27:20:48:01,481 INFO     [evaluator.py:362] Running generate_until requests\n",
            "Running generate_until requests:   0% 0/11873 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
            "Determined Largest batch size: 4\n",
            "Running generate_until requests:  56% 6705/11873 [24:54<12:23,  6.95it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "J0q9ubwufyJo"
      ],
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}